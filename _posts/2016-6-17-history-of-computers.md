---
layout: post
title: Codewars
---

Computers truly came into their own as great inventions in the last two decades of the 20th century. But their history stretches back more than 2500 years to the abacus: a simple calculator made from beads and wires, which is still used in some parts of the world today.
The difference between an ancient abacus and a modern computer seems vast, but the principle—making repeated calculations more quickly than the human brain—is exactly the same.In the current world, it’s almost impossible to imagine that someone can live without computers. Computers have become an electronic device of almost every day use for individuals of every age. They are essential in almost all the business dealings that are made nowadays. The most that any industry has gained from the discovery of the computers is the business industry because of its nature. Computers have gained significance as they have improved the efficiency and productivity of work done.
Large amounts of information in industrial and business sectors as well as in the personal lives are stored on computers.

## The First Computers

The first electronic computers, invented in the 1940s, used electronic switches and vacuum tubes to store data. The vacuum tubes could only store about 32 to 512 bytes therefore thousands of these tubes were recquired for these computers to be useful. This meant that the first electronic computers were huge and would recquire lots of space.The first substantial computer was the giant ENIAC machine by John W. Mauchly and J. Presper Eckert at the University of Pennsylvania. ENIAC used nearly 1800 vacuum tubes. Storage of all those vacuum tubes and the machinery required to keep the cool took up over 167 square meters of floor space. ENIAC used punch card input and output.The first electronic computers used a lot of electricity, had many moving parts, therefore they brokedown oftenly, used up a lot of space and could only be used by highly trained people. Despite this they were very useful especially in the military world. A calculation that would take a human several hours to complete would take a computer several seconds

## Progression of Hardware

In the 1950s, the transistor was invented. This replaced the vacuum tubes that were widely used in computers at the time. The transistors produced much less heat than the vacuum tubes. This meant the costs of running a computer was reduced. Transistors, however, had their problems too. The main problem was that transistors, like other electronic components, needed to be soldered together. As a result, the more complex the circuits became, the more complicated and numerous the connections between the individual transistors and the likelihood of faulty wiring increased. This problem was solved in 1958 by the invention of the integrated circuit or chip. A chip is really a collection of tiny transistors which are connected together when the transistor is manufactured. Thus, the need for soldering together large numbers of transistors was practically nullified; now only connections were needed to other electronic components. In addition to saving space, the speed of the machine was now increased since there was a diminished distance that the electrons had to follow.
